{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - Sentiment Analysis - Big Richard Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xqzxNN53FwEQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re \n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "import umap\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Talu88EbFxXR"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/Corona_NLP_train.csv' , encoding = 'latin_1')\n",
    "df_val = pd.read_csv('data/Corona_NLP_test.csv' , encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S-njnTm_G8wb"
   },
   "outputs": [],
   "source": [
    "training = df_train[['OriginalTweet', 'Sentiment']]\n",
    "validation = df_val[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Renaming Columns and Reducing the Amount of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.rename({\n",
    "    \"OriginalTweet\": \"text\",\n",
    "    \"Sentiment\": \"label\"\n",
    "}, axis=\"columns\", inplace=True)\n",
    "\n",
    "validation.rename({\n",
    "    \"OriginalTweet\": \"text\",\n",
    "    \"Sentiment\": \"label\"\n",
    "}, axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 5 classes to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8rV6SyZHgGa",
    "outputId": "491a0a48-4ca9-44f6-b5c5-8050e91a1a72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.438467\n",
       "0    0.374128\n",
       "1    0.187404\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classes_def(x):\n",
    "    '''\n",
    "    Makes the label variable have 3 classes instead of 5\n",
    "    '''\n",
    "    \n",
    "    if x ==  \"Extremely Positive\":\n",
    "        return \"2\"\n",
    "    elif x == \"Extremely Negative\":\n",
    "        return \"0\"\n",
    "    elif x == \"Negative\":\n",
    "        return \"0\"\n",
    "    elif x ==  \"Positive\":\n",
    "        return \"2\"\n",
    "    else:\n",
    "        return \"1\"\n",
    "\n",
    "training['label'] = training['label'].apply(lambda x:classes_def(x))\n",
    "validation['label'] = validation['label'].apply(lambda x:classes_def(x))\n",
    "\n",
    "training.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(df, colname):\n",
    "    df[colname] = df[colname].str.split()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(df, colname):\n",
    "    stop_words = stopwords.words('english')\n",
    "    df[colname] = df[colname].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_tokenize_sentence(df, colname):\n",
    "    df[colname] = df[colname].map(lambda word: ' '.join(word))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_removal(df, column):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, lowercases it and removes the following elements:\n",
    "    1. URLs\n",
    "    2. Mentions \"@\" and Usernames\n",
    "    3. HTML\n",
    "    4. Numbers\n",
    "    5. Punctuation\n",
    "    6. Hashtags\n",
    "    Optional : 7. Extra Space\n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].str.lower()\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        df[column][i] = re.sub(r'https?://\\S+|www\\.\\S+', \"\", df[column][i]) # urls\n",
    "        df[column][i] = re.sub(r\"@\\w+\", \"\", df[column][i]) # mentions\n",
    "        df[column][i] = re.sub(r\"<.*?>\", \"\", df[column][i]) # html\n",
    "        df[column][i] = re.sub(r\"\\d+\", \"\", df[column][i]) # numbers\n",
    "        df[column][i] = re.sub(r\"[^\\w\\s\\d]\", \"\", df[column][i]) # punctuation\n",
    "        df[column][i] = re.sub(r\"#\\w+\", \"\", df[column][i]) # hashtags\n",
    "        #df[column][i] = re.sub(r\"\\s+\", \"\", df[column][i]) # extra space\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(df, colname):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Tokenize sentences\n",
    "    2. Remove all stopwords\n",
    "    3. convert tokenized text to text\n",
    "    \"\"\"\n",
    "    \n",
    "    df = (\n",
    "        df\n",
    "        .pipe(tokenize_sentence, colname)\n",
    "        .pipe(remove_stop_words, colname)\n",
    "        .pipe(reverse_tokenize_sentence, colname)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and  and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me ready to go at supermarket during the covid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>you know itâs getting tough when   is rationin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>well newused rift s are going for  on amazon ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0                                              and  and      1\n",
       "1      advice talk to your neighbours family to excha...     2\n",
       "2      coronavirus australia woolworths to give elder...     2\n",
       "3      my food stock is not the only one which is emp...     2\n",
       "4      me ready to go at supermarket during the covid...     0\n",
       "...                                                  ...   ...\n",
       "41152  airline pilots offering to stock supermarket s...     1\n",
       "41153  response to complaint not provided citing covi...     0\n",
       "41154  you know itâs getting tough when   is rationin...     2\n",
       "41155  is it wrong that the smell of hand sanitizer i...     1\n",
       "41156   well newused rift s are going for  on amazon ...     0\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_removal(training, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus australia woolworths give elderly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food stock one empty please dont panic enough ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ready go supermarket covid outbreak im paranoi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>airline pilots offering stock supermarket shel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>response complaint provided citing covid relat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>know itâs getting tough rationing toilet paper...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>wrong smell hand sanitizer starting turn coron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>well newused rift going amazon rn although nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0                                                            1\n",
       "1      advice talk neighbours family exchange phone n...     2\n",
       "2      coronavirus australia woolworths give elderly ...     2\n",
       "3      food stock one empty please dont panic enough ...     2\n",
       "4      ready go supermarket covid outbreak im paranoi...     0\n",
       "...                                                  ...   ...\n",
       "41152  airline pilots offering stock supermarket shel...     1\n",
       "41153  response complaint provided citing covid relat...     0\n",
       "41154  know itâs getting tough rationing toilet paper...     2\n",
       "41155  wrong smell hand sanitizer starting turn coron...     1\n",
       "41156  well newused rift going amazon rn although nor...     0\n",
       "\n",
       "[41157 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaning(training, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trending new yorkers encounter empty supermark...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i couldnt find hand sanitizer at fred mey...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find out how you can protect yourself and love...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic buying hits newyork city as anxious shop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toiletpaper dunnypaper coronavirus coronavirus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>meanwhile in a supermarket in israel  people d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>did you panic buy a lot of nonperishable items...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>asst prof of economics  was on  talking about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>gov need to do somethings instead of biar je r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>i and  members are committed to the safety of ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     trending new yorkers encounter empty supermark...     0\n",
       "1     when i couldnt find hand sanitizer at fred mey...     2\n",
       "2     find out how you can protect yourself and love...     2\n",
       "3     panic buying hits newyork city as anxious shop...     0\n",
       "4     toiletpaper dunnypaper coronavirus coronavirus...     1\n",
       "...                                                 ...   ...\n",
       "3793  meanwhile in a supermarket in israel  people d...     2\n",
       "3794  did you panic buy a lot of nonperishable items...     0\n",
       "3795  asst prof of economics  was on  talking about ...     1\n",
       "3796  gov need to do somethings instead of biar je r...     0\n",
       "3797  i and  members are committed to the safety of ...     2\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_removal(validation, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trending new yorkers encounter empty supermark...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>couldnt find hand sanitizer fred meyer turned ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find protect loved ones coronavirus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panic buying hits newyork city anxious shopper...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toiletpaper dunnypaper coronavirus coronavirus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>meanwhile supermarket israel people dance sing...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>panic buy lot nonperishable items echo needs f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>asst prof economics talking recent research co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>gov need somethings instead biar je rakyat ass...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>members committed safety employees endusers mo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "0     trending new yorkers encounter empty supermark...     0\n",
       "1     couldnt find hand sanitizer fred meyer turned ...     2\n",
       "2                   find protect loved ones coronavirus     2\n",
       "3     panic buying hits newyork city anxious shopper...     0\n",
       "4     toiletpaper dunnypaper coronavirus coronavirus...     1\n",
       "...                                                 ...   ...\n",
       "3793  meanwhile supermarket israel people dance sing...     2\n",
       "3794  panic buy lot nonperishable items echo needs f...     0\n",
       "3795  asst prof economics talking recent research co...     1\n",
       "3796  gov need somethings instead biar je rakyat ass...     0\n",
       "3797  members committed safety employees endusers mo...     2\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaning(validation, \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) The Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all-MiniLM-L6-v2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN ONLY ONCE\n",
    "\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#embeddings = model.encode(training[\"text\"], show_progress_bar=True)\n",
    "#np.savetxt(\"data/new_training_embeddings.txt.gz\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.loadtxt(\"data/new_training_embeddings.txt.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8f33e949de484389b1c9fea007d3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RUN ONLY ONCE\n",
    "\n",
    "#validation_embeddings = model.encode(validation[\"text\"], show_progress_bar=True)\n",
    "#np.savetxt(\"data/validation_embeddings.txt.gz\", validation_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Clustering the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings = umap.UMAP(\n",
    "    n_neighbors=10,\n",
    "    n_components=10,\n",
    "    metric='cosine'\n",
    ").fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=100,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom'\n",
    ").fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "#plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Main words in each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame(training[\"text\"], columns=[\"text\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'text': ' '.join})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which gives us the most common word in a cluster : C-TFIDF \n",
    "\n",
    "Source: https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(\n",
    "        ngram_range=ngram_range,\n",
    "        stop_words=\"english\"\n",
    "    ).fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    w = t.sum(axis=1)\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(\n",
    "        np.divide(m, sum_t)\n",
    "    ).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "  \n",
    "tf_idf, count = c_tf_idf(docs_per_topic.text.values, m=len(training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .text\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"text\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes = extract_topic_sizes(docs_df)\n",
    "topic_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Words in Different Clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('supermarket', 0.02212497443343997),\n",
       " ('covid', 0.021287502594052748),\n",
       " ('coronavirus', 0.01961725905533167),\n",
       " ('food', 0.019594544833979818),\n",
       " ('people', 0.018306510298197784)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('coughing', 0.2482873503224445),\n",
       " ('teens', 0.2437752310872849),\n",
       " ('produce', 0.19909559565044607),\n",
       " ('teenagers', 0.16871113197647616),\n",
       " ('outofcontrol', 0.10437505660231376)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cough', 0.2533486994121698),\n",
       " ('shows', 0.16144377338845353),\n",
       " ('spread', 0.12976419347888116),\n",
       " ('air', 0.12425763356835794),\n",
       " ('video', 0.1030338426449433)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Draft ML2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
